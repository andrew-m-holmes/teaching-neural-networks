{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bda9a1-6884-4b87-b7da-55277b1cb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import logging\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1805f1-f4cf-42ea-bb68-d4ebae44974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "train = dataset.get(\"train\")\n",
    "val = dataset.get(\"validation\")\n",
    "test = dataset.get(\"test\")\n",
    "eval = concatenate_datasets([val, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b2a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/git/teaching-neural-networks/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classes = len(train.unique(\"label\"))\n",
    "name = \"google-bert/bert-large-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(name)\n",
    "pad_id = tokenizer.get_vocab().get(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0da779-7228-4953-92cd-b5fde4802756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sequence: 87\n"
     ]
    }
   ],
   "source": [
    "length =0\n",
    "for example in train:\n",
    "    length = max(length, len(tokenizer(example[\"text\"]).input_ids))\n",
    "\n",
    "for example in eval:\n",
    "    length = max(length, len(tokenizer(example[\"text\"]).input_ids))\n",
    "\n",
    "print(f\"longest sequence: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736f24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(examples):\n",
    "    examples = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=96,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_dataset = train.map(\n",
    "    pre_process, batch_size=True, num_proc=2, remove_columns=[\"text\"]\n",
    ")\n",
    "eval_dataset = eval.map(\n",
    "    pre_process, batch_size=True, num_proc=2, remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b62974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = {\"input_ids\": [], \"token_type_ids\": [], \"attention_mask\": []}\n",
    "    labels = []\n",
    "\n",
    "    for example in batch:\n",
    "        inputs[\"input_ids\"].append(example[\"input_ids\"])\n",
    "        inputs[\"token_type_ids\"].append(example[\"token_type_ids\"])\n",
    "        inputs[\"attention_mask\"].append(example[\"attention_mask\"])\n",
    "        labels.append(example[\"label\"])\n",
    "\n",
    "    inputs[\"input_ids\"] = torch.tensor(inputs[\"input_ids\"]).long()\n",
    "    inputs[\"token_type_ids\"] = torch.tensor(inputs[\"token_type_ids\"]).long()\n",
    "    inputs[\"attention_mask\"] = torch.tensor(inputs[\"attention_mask\"]).long()\n",
    "    labels = torch.tensor(labels).long()\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82df0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "testloader = data.DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "\n",
    "def to(inputs, labels, device, non_blocking):\n",
    "    inputs = dict(\n",
    "        map(\n",
    "            lambda item: (item[0], item[1].to(device, non_blocking=non_blocking)),\n",
    "            inputs.items(),\n",
    "        )\n",
    "    )\n",
    "    labels = labels.to(device, non_blocking=True)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cfa0102-5255-4c62-bc66-c7d43179b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tnn.BertForClassification(classes=classes, hidden_size=1024, name=name)\n",
    "lr = 5e-5\n",
    "factor = 0.05\n",
    "patience = 3\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "scheduler = ReduceLROnPlateau(optim, mode=\"min\", factor=factor, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400d89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tnn.Trainer(\n",
    "    model,\n",
    "    optim,\n",
    "    loss_fn,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    scheduler=scheduler,\n",
    "    epochs=50,\n",
    "    unpack_inputs=True,\n",
    "    save_weights=True,\n",
    "    device=device,\n",
    "    to_fn=to,\n",
    "    path=\"../training/emotions-bert-sgdm.h5\",\n",
    "    verbose=True,\n",
    "    profile=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b3b2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model using cuda\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-0\n",
      "training started\n",
      "(epoch: 1/50): (train loss: 1.3684, test loss: 1.2722, train acc: 33.84%, test acc: 36.40%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8002.0 MB)\n",
      "(duration info): (epoch duration: 0:02:07, elapsed time: 0:02:07)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-1\n",
      "(epoch: 2/50): (train loss: 1.1564, test loss: 0.9933, train acc: 39.65%, test acc: 44.82%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:04:14)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-2\n",
      "(epoch: 3/50): (train loss: 0.9405, test loss: 0.8076, train acc: 45.15%, test acc: 50.88%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:06:21)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-3\n",
      "(epoch: 4/50): (train loss: 0.7534, test loss: 0.6268, train acc: 51.52%, test acc: 55.38%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:08:28)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-4\n",
      "(epoch: 5/50): (train loss: 0.5507, test loss: 0.4443, train acc: 56.61%, test acc: 60.50%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:10:36)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-5\n",
      "(epoch: 6/50): (train loss: 0.3928, test loss: 0.3204, train acc: 61.06%, test acc: 63.70%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:12:43)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-6\n",
      "(epoch: 7/50): (train loss: 0.2969, test loss: 0.2480, train acc: 63.11%, test acc: 64.83%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 0:14:50)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-7\n",
      "(epoch: 8/50): (train loss: 0.2416, test loss: 0.2180, train acc: 64.31%, test acc: 65.72%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 0:16:57)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-8\n",
      "(epoch: 9/50): (train loss: 0.1996, test loss: 0.2107, train acc: 65.12%, test acc: 65.90%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:19:04)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-9\n",
      "(epoch: 10/50): (train loss: 0.1858, test loss: 0.1999, train acc: 65.53%, test acc: 65.67%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:21:12)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-10\n",
      "(epoch: 11/50): (train loss: 0.1634, test loss: 0.1841, train acc: 65.98%, test acc: 65.90%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:23:19)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-11\n",
      "(epoch: 12/50): (train loss: 0.1510, test loss: 0.1764, train acc: 66.09%, test acc: 66.20%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:25:27)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-12\n",
      "(epoch: 13/50): (train loss: 0.1423, test loss: 0.1718, train acc: 66.37%, test acc: 66.00%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:27:34)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-13\n",
      "(epoch: 14/50): (train loss: 0.1372, test loss: 0.1841, train acc: 66.46%, test acc: 66.12%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:29:41)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-14\n",
      "(epoch: 15/50): (train loss: 0.1275, test loss: 0.1797, train acc: 66.64%, test acc: 66.07%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:31:49)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-15\n",
      "(epoch: 16/50): (train loss: 0.1270, test loss: 0.1626, train acc: 66.54%, test acc: 66.60%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:33:56)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-16\n",
      "(epoch: 17/50): (train loss: 0.1194, test loss: 0.1543, train acc: 66.81%, test acc: 66.55%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:36:03)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-17\n",
      "(epoch: 18/50): (train loss: 0.1097, test loss: 0.1729, train acc: 67.26%, test acc: 66.33%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:38:11)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-18\n",
      "(epoch: 19/50): (train loss: 0.1095, test loss: 0.1636, train acc: 67.22%, test acc: 66.07%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:40:18)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-19\n",
      "(epoch: 20/50): (train loss: 0.1021, test loss: 0.1573, train acc: 67.38%, test acc: 66.40%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:42:26)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-20\n",
      "(epoch: 21/50): (train loss: 0.1016, test loss: 0.1612, train acc: 67.31%, test acc: 66.30%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:44:33)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-21\n",
      "(epoch: 22/50): (train loss: 0.0921, test loss: 0.1605, train acc: 67.81%, test acc: 66.47%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:46:40)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-22\n",
      "(epoch: 23/50): (train loss: 0.0894, test loss: 0.1586, train acc: 67.87%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:48:48)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-23\n",
      "(epoch: 24/50): (train loss: 0.0887, test loss: 0.1600, train acc: 67.86%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:50:55)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-24\n",
      "(epoch: 25/50): (train loss: 0.0905, test loss: 0.1591, train acc: 67.90%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:53:02)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-25\n",
      "(epoch: 26/50): (train loss: 0.0883, test loss: 0.1593, train acc: 67.85%, test acc: 66.67%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:55:10)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-26\n",
      "(epoch: 27/50): (train loss: 0.0889, test loss: 0.1593, train acc: 67.88%, test acc: 66.67%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:57:17)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-27\n",
      "(epoch: 28/50): (train loss: 0.0866, test loss: 0.1594, train acc: 67.88%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 0:59:24)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-28\n",
      "(epoch: 29/50): (train loss: 0.0861, test loss: 0.1593, train acc: 67.97%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:01:31)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-29\n",
      "(epoch: 30/50): (train loss: 0.0870, test loss: 0.1593, train acc: 67.69%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:03:39)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-30\n",
      "(epoch: 31/50): (train loss: 0.0883, test loss: 0.1593, train acc: 67.90%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:05:46)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-31\n",
      "(epoch: 32/50): (train loss: 0.0902, test loss: 0.1593, train acc: 67.78%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:07:53)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-32\n",
      "(epoch: 33/50): (train loss: 0.0888, test loss: 0.1593, train acc: 67.87%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:10:01)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-33\n",
      "(epoch: 34/50): (train loss: 0.0881, test loss: 0.1593, train acc: 67.88%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:12:08)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-34\n",
      "(epoch: 35/50): (train loss: 0.0896, test loss: 0.1593, train acc: 67.73%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 1:14:15)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-35\n",
      "(epoch: 36/50): (train loss: 0.0861, test loss: 0.1593, train acc: 67.99%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:16:23)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-36\n",
      "(epoch: 37/50): (train loss: 0.0873, test loss: 0.1593, train acc: 67.88%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:18:30)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-37\n",
      "(epoch: 38/50): (train loss: 0.0885, test loss: 0.1593, train acc: 67.68%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:20:37)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-38\n",
      "(epoch: 39/50): (train loss: 0.0884, test loss: 0.1593, train acc: 67.96%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 1:22:44)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-39\n",
      "(epoch: 40/50): (train loss: 0.0882, test loss: 0.1593, train acc: 67.85%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:24:51)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-40\n",
      "(epoch: 41/50): (train loss: 0.0875, test loss: 0.1593, train acc: 67.88%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 1:26:59)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-41\n",
      "(epoch: 42/50): (train loss: 0.0867, test loss: 0.1593, train acc: 67.89%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:29:06)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-42\n",
      "(epoch: 43/50): (train loss: 0.0895, test loss: 0.1593, train acc: 67.76%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 1:31:13)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-43\n",
      "(epoch: 44/50): (train loss: 0.0911, test loss: 0.1593, train acc: 67.71%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:05, elapsed time: 1:33:20)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-44\n",
      "(epoch: 45/50): (train loss: 0.0909, test loss: 0.1593, train acc: 67.79%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:35:27)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-45\n",
      "(epoch: 46/50): (train loss: 0.0879, test loss: 0.1593, train acc: 67.79%, test acc: 66.65%)\n",
      "(gpu memory profile): (average allocated: 3955.0 MB, average reserved: 8005.0 MB)\n",
      "(duration info): (epoch duration: 0:02:06, elapsed time: 1:37:36)\n",
      "weights saved to ../training/emotions-bert-sgdm.h5/trajectory/weights-epoch-46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sgdm_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/teaching-neural-networks/tnn/trainer.py:128\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 128\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m epoch_train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_correct(logits, labels)\n\u001b[1;32m    130\u001b[0m n_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgdm_metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff52493-8d90-409c-8630-2fb8f61df18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tnn.BertForClassification(classes=classes, hidden_size=1024, name=name)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optim, mode=\"min\", factor=factor, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba324162-4874-478a-a37b-b1d6694800ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model\n",
    "trainer.optim = optim\n",
    "trainer.scheduler = scheduler\n",
    "trainer.path = \"../training/emotions-bert-sgdm-nesterov.h5\"\n",
    "sgdm_nesterov_metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17267b-9ddd-4956-ae13-030011365b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tnn.BertForClassification(classes=classes, hidden_size=1024, name=name)\n",
    "optim = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99)\n",
    "scheduler = ReduceLROnPlateau(optim, mode=\"min\", factor=factor, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03546c-9543-4e1c-ae50-7239bd87ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model\n",
    "trainer.optim = optim\n",
    "trainer.scheduler = scheduler\n",
    "trainer.path = \"../training/emotions-bert-rmsprop.h5\"\n",
    "rmsprop_metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb802bf-837c-4927-b666-9a72b5963957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tnn.BertForClassification(classes=classes, hidden_size=1024, name=name)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999)\n",
    "scheduler = ReduceLROnPlateau(optim, mode=\"min\", factor=factor, patience=patience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3aec5-df70-4baa-a8e3-2d233aa4a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model\n",
    "trainer.optim = optim\n",
    "trainer.scheduler = scheduler\n",
    "trainer.path = \"../training/emotions-bert-adam.h5\"\n",
    "adam_metrics = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
