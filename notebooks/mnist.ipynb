{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571b0449-b5b7-4a9c-89cb-e0f8e12a61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as f\n",
    "\n",
    "from datasets import load_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from src.trainer import Trainer\n",
    "from src.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4608e2-139f-4dfc-8936-4f69c7b075f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ylecun/mnist\", num_proc=2)\n",
    "train = dataset.get(\"train\")\n",
    "test = dataset.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48c375d-702b-4972-86c3-77e2c194dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(example):\n",
    "    arr = np.reshape(example[\"image\"], -1) / 255.0\n",
    "    example[\"input\"] = arr\n",
    "    return example\n",
    "\n",
    "train_dataset = train.map(to_numpy, num_proc=2).select_columns([\"input\", \"label\"])\n",
    "test_dataset = test.map(to_numpy, num_proc=2).select_columns([\"input\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48769364-b4d3-421c-996a-cd55523d85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = torch.tensor([ex[\"input\"] for ex in batch]).float()\n",
    "    labels = torch.tensor([ex[\"label\"] for ex in batch]).long()\n",
    "    return inputs, labels\n",
    "\n",
    "trainloader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=False, collate_fn=collate_fn, num_workers=2)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=1024, shuffle=False, drop_last=False, collate_fn=collate_fn, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a160b8da-2a9c-4a34-ab79-38e19e8af72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(784, 512)\n",
    "        self.drop_1 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(512, 512)\n",
    "        self.drop_2 = nn.Dropout(0.25)\n",
    "        self.linear_3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop_1(f.relu(self.linear_1(x)))\n",
    "        x = self.drop_2(f.relu(self.linear_2(x)))\n",
    "        return dict(logits=f.relu(self.linear_3(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411e3fb2-cc90-443a-8bf0-cbaa8e76dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(MLP())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34bbe022-f35b-4a62-ae98-ff29cdf9cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optim, loss_fn, trainloader, testloader, path=\"./train.h5\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b78b981-c0bc-41c2-a3ae-fc9891613bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started\n",
      "(epoch: 1): train loss: 0.3334, test loss: 0.2650, train acc: 0.9035, test acc: 0.9234\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-1\n",
      "(epoch: 2): train loss: 0.3180, test loss: 0.2533, train acc: 0.9080, test acc: 0.9266\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-2\n",
      "(epoch: 3): train loss: 0.3066, test loss: 0.2421, train acc: 0.9113, test acc: 0.9292\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-3\n",
      "(epoch: 4): train loss: 0.2935, test loss: 0.2329, train acc: 0.9142, test acc: 0.9320\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-4\n",
      "(epoch: 5): train loss: 0.2820, test loss: 0.2236, train acc: 0.9178, test acc: 0.9351\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-5\n",
      "(epoch: 6): train loss: 0.2731, test loss: 0.2160, train acc: 0.9205, test acc: 0.9368\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-6\n",
      "(epoch: 7): train loss: 0.2635, test loss: 0.2067, train acc: 0.9234, test acc: 0.9408\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-7\n",
      "(epoch: 8): train loss: 0.2550, test loss: 0.1999, train acc: 0.9254, test acc: 0.9415\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-8\n",
      "(epoch: 9): train loss: 0.2457, test loss: 0.1928, train acc: 0.9282, test acc: 0.9442\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-9\n",
      "(epoch: 10): train loss: 0.2390, test loss: 0.1872, train acc: 0.9297, test acc: 0.9457\n",
      "weights saved to ./train.h5/trajectory/weights-epoch-10\n",
      "metrics written to ./train.h5/metrics\n",
      "training complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_losses': [0.33337495325089517,\n",
       "  0.31802281537162724,\n",
       "  0.30656916325661676,\n",
       "  0.2934945853216562,\n",
       "  0.2820141342466574,\n",
       "  0.27305524947165427,\n",
       "  0.26348362365828903,\n",
       "  0.2550256851194764,\n",
       "  0.24571655692258623,\n",
       "  0.23900088671046787],\n",
       " 'test_losses': [0.2649575486779213,\n",
       "  0.2533253595232964,\n",
       "  0.2420528218150139,\n",
       "  0.2328703783452511,\n",
       "  0.22356420755386353,\n",
       "  0.21602563187479973,\n",
       "  0.20673343017697335,\n",
       "  0.1998528406023979,\n",
       "  0.19284727349877356,\n",
       "  0.18716058358550072],\n",
       " 'train_accs': [0.9034666666666666,\n",
       "  0.908,\n",
       "  0.9112833333333333,\n",
       "  0.9142,\n",
       "  0.9178166666666666,\n",
       "  0.9205166666666666,\n",
       "  0.9234333333333333,\n",
       "  0.92535,\n",
       "  0.9282333333333334,\n",
       "  0.9297333333333333],\n",
       " 'test_accs': [0.9234,\n",
       "  0.9266,\n",
       "  0.9292,\n",
       "  0.932,\n",
       "  0.9351,\n",
       "  0.9368,\n",
       "  0.9408,\n",
       "  0.9415,\n",
       "  0.9442,\n",
       "  0.9457]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c13731-be93-4fd6-8b86-ced77862935e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
